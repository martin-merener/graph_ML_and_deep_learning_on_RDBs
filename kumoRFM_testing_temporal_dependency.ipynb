{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1e2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kumoai.experimental.rfm as rfm, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime, timedelta, timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60032560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-17 09:50:28 - kumoai:196 - INFO] Successfully initialized the Kumo SDK against deployment https://kumorfm.ai/api, with log level INFO.\n"
     ]
    }
   ],
   "source": [
    "home_api_key_file = Path.home() / \"kumoai_key.txt\"\n",
    "with open(home_api_key_file, \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "os.environ[\"KUMO_API_KEY\"] = api_key\n",
    "\n",
    "rfm.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dadad4",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create a synthetic dataset with the purpose of testing how KumoRFM deals with temporal dependency that is not in the transactional history, but instead in a user type variable that can change over time.\n",
    "Essentially, there are users of 2 types (premium/free), and premium users can do actions that free users cannot.\n",
    "The exercise is about testing if KumoRFM detects this dependency and consideres it for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db9398",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "- Create a synthetic dataset representing users of 2 types (tier free or tier premium), uploading files of different sizes, and with their user tiers changing over time.\n",
    "- While on Premium tier, users can upload any size. \n",
    "- While on free tier, users can upload files below 10GB. \n",
    "- For simplicity, there are only 2 sizes: 5GB and 50GB.\n",
    "- Users can change their tier no earlier than 24 hours after the last change. \n",
    "- Within an hour of becoming premium, the likelihood of the user uploading a 50GB is much higher than after the first hour.\n",
    "- There are 50 users, covering 5 cohorts:\n",
    "    - Always premium (unknown start) → a single interval that spans the whole window.\n",
    "    - Always free → a single interval that spans the whole window.\n",
    "    - Premium → Free once (≥24h after start).\n",
    "    - Free → Premium once (≥24h).\n",
    "    - Free → Premium → Free (each change ≥24h apart; all within window).\n",
    "- The history of transactions last 10 days from March 1st to March 11th, 2025.\n",
    "- The prediction tasks will be done for different users, at different points in time, predicting their likelihood of uploading a 50GB file within the next hour.\n",
    "- Expectations: \n",
    "    - For users that are Free tier, this should be 0. \n",
    "    - For users that just became Premium it should be high during the first hour. \n",
    "    - For users that had been Premium for sometime (beyond the first hour), it should be >> 0 but not as high. \n",
    "\n",
    "### Tables\n",
    "\n",
    "- users (50 users). This set is just random ids and names.\n",
    "    - user_id (PK)\n",
    "    - name\n",
    "\n",
    "- items (80 different items: 45 of 5 GB, 35 of 50 GB). Basically random ids.\n",
    "    - item_id (PK)\n",
    "    - size_gb in {5, 50}\n",
    "\n",
    "- tiers. See creation process below.\n",
    "    - tier_status_id (PK)\n",
    "    - user_id (FK -> users.user_id)\n",
    "    - from_datetime\n",
    "    - until_datetime\n",
    "    - status in {'free', 'premium'}\n",
    "\n",
    "\n",
    "- uploads. See creation process below.\n",
    "    - upload_id (PK)\n",
    "    - user_id (FK -> users.user_id)\n",
    "    - item_id (FK -> items.item_id)\n",
    "    - datetime\n",
    "\n",
    "\n",
    "### Creation process (not efficient, prioritize simplicity/clarity)\n",
    "\n",
    "- tiers:\n",
    "    - User ids from 1 to 10: always premium: 1 row in tiers.\n",
    "        - from_date = START, until_date = END, status = 'premium'\n",
    "    - User ids from 11 to 20: always free: 1 row in tiers.\n",
    "        - from_date = START, until_date = END: status = 'free'    \n",
    "    - User ids from 21 to 30: premium to free: 2 rows in tiers.\n",
    "        - Take a random date X in (START, END)\n",
    "        - from_date = START, until_date = X: status = 'premium'\n",
    "        - from_date = X, until_date = END: status = 'free'\n",
    "    - user ids from 31 to 40: free to premium: 2 rows in tiers.\n",
    "        - Take a random date X in (START, END)\n",
    "        - from_date = START, until_date = X: status = 'free'\n",
    "        - from_date = X, until_date = END: status = 'premium'\n",
    "    - user ids from 41 to 50: free to premium to free: 3 rows in tiers.\n",
    "        - Take random dates X1 < X2 in (START, END)\n",
    "        - from_date = START, until_date = X1: status = 'free'\n",
    "        - from_date = X1, until_date = X2: status = 'premium'\n",
    "        - from_date = X2, until_date = END: status = 'free'\n",
    "\n",
    "- uploads:\n",
    "    - for each tier_status_id, create the uploads in the corresponding interval.\n",
    "    - Given a tier_status_id, get the details: user_id, from_date, until_date, status.\n",
    "    - If status = 'free':\n",
    "        - compute the number of hours delta_h from from_date to until_date.\n",
    "        - take a sample of r = ceil(delta_h/5) times in (from_date, until_date).\n",
    "        - use those as datetime.\n",
    "        - generate the corresponding number of rows for uploads.\n",
    "        - keep track of the last generated upload_id.\n",
    "        - the user_id is the current one.\n",
    "        - items_id's should be taken at random from those with 5GB.\n",
    "    - if status = 'premium':\n",
    "        - Do the same as for free.\n",
    "        - Then do the same as for free, but sampling ceil(delta_h/10) times in (from_date, until_date), and from 50GB items.\n",
    "        - And then:\n",
    "        - compute the from_date_plus as 1 hour after from_date.\n",
    "        - Generate 10 datetimes in (from_date, from_date_plus), each with probability 50%.\n",
    "        - use those as datetime, generate the corresponding number of rows for uploads.\n",
    "        - keep track of the last generated upload_id.\n",
    "        - use the same user id, and sample item_id's from those with 50GB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b872da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote: users.csv items.csv tiers.csv uploads.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "START = datetime(2025, 3, 1, 0, 0, 0, tzinfo=timezone.utc)\n",
    "END   = datetime(2025, 3, 11, 0, 0, 0, tzinfo=timezone.utc)  # half-open [START, END)\n",
    "\n",
    "USERS_CSV   = \"users.csv\"\n",
    "ITEMS_CSV   = \"items.csv\"\n",
    "TIERS_CSV   = \"tiers.csv\"\n",
    "UPLOADS_CSV = \"uploads.csv\"\n",
    "\n",
    "N_USERS = 50\n",
    "N_ITEMS_5GB = 45\n",
    "N_ITEMS_50GB = 35\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def rand_dt(a, b):\n",
    "    total_sec = int((b - a).total_seconds())\n",
    "    if total_sec <= 1:\n",
    "        return a + timedelta(seconds=1)\n",
    "    off = random.randint(1, total_sec - 1)\n",
    "    return a + timedelta(seconds=off)\n",
    "\n",
    "def sample_times(n, a, b):\n",
    "    return [rand_dt(a, b) for _ in range(n)]\n",
    "\n",
    "def hours_between(a, b):\n",
    "    return (b - a).total_seconds() / 3600.0\n",
    "\n",
    "# ----------------------------\n",
    "# 1) users\n",
    "# ----------------------------\n",
    "users = []\n",
    "for uid in range(1, N_USERS + 1):\n",
    "    users.append([uid, f\"User {uid:03d}\"])\n",
    "\n",
    "# ----------------------------\n",
    "# 2) items\n",
    "# ----------------------------\n",
    "items = []\n",
    "for iid in range(1, N_ITEMS_5GB + 1):\n",
    "    items.append([iid, 5])\n",
    "for iid in range(N_ITEMS_5GB + 1, N_ITEMS_5GB + N_ITEMS_50GB + 1):\n",
    "    items.append([iid, 50])\n",
    "\n",
    "item_ids_5 = [row[0] for row in items if row[1] == 5]\n",
    "item_ids_50 = [row[0] for row in items if row[1] == 50]\n",
    "\n",
    "# ----------------------------\n",
    "# 3) tiers\n",
    "# ----------------------------\n",
    "tiers = []\n",
    "tier_status_id = 1\n",
    "\n",
    "def add_interval(uid, a, b, status):\n",
    "    global tier_status_id\n",
    "    tiers.append([tier_status_id, uid, a, b, status])\n",
    "    tier_status_id += 1\n",
    "\n",
    "# always premium\n",
    "for uid in range(1, 11):\n",
    "    add_interval(uid, START, END, \"premium\")\n",
    "\n",
    "# always free\n",
    "for uid in range(11, 21):\n",
    "    add_interval(uid, START, END, \"free\")\n",
    "\n",
    "# premium -> free\n",
    "for uid in range(21, 31):\n",
    "    lo = START + timedelta(hours=24)\n",
    "    hi = END - timedelta(hours=24)\n",
    "    x = lo + timedelta(seconds=random.randint(0, int((hi - lo).total_seconds())))\n",
    "    add_interval(uid, START, x, \"premium\")\n",
    "    add_interval(uid, x, END, \"free\")\n",
    "\n",
    "# free -> premium\n",
    "for uid in range(31, 41):\n",
    "    lo = START + timedelta(hours=24)\n",
    "    hi = END - timedelta(hours=24)\n",
    "    x = lo + timedelta(seconds=random.randint(0, int((hi - lo).total_seconds())))\n",
    "    add_interval(uid, START, x, \"free\")\n",
    "    add_interval(uid, x, END, \"premium\")\n",
    "\n",
    "# free -> premium -> free\n",
    "for uid in range(41, 51):\n",
    "    lo1 = START + timedelta(hours=24)\n",
    "    hi1 = END - timedelta(hours=48)\n",
    "    x1 = lo1 + timedelta(seconds=random.randint(0, int((hi1 - lo1).total_seconds())))\n",
    "\n",
    "    lo2 = x1 + timedelta(hours=24)\n",
    "    hi2 = END - timedelta(seconds=1)\n",
    "    if lo2 >= hi2:\n",
    "        hi2 = x1 + timedelta(hours=48)\n",
    "    x2 = lo2 + timedelta(seconds=random.randint(0, int((hi2 - lo2).total_seconds())))\n",
    "\n",
    "    add_interval(uid, START, x1, \"free\")\n",
    "    add_interval(uid, x1, x2, \"premium\")\n",
    "    add_interval(uid, x2, END, \"free\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) uploads\n",
    "# ----------------------------\n",
    "uploads = []\n",
    "upload_id = 1\n",
    "\n",
    "for row in tiers:\n",
    "    uid = row[1]\n",
    "    a = row[2]\n",
    "    b = row[3]\n",
    "    status = row[4]\n",
    "\n",
    "    delta_h = hours_between(a, b)\n",
    "    if delta_h <= 0:\n",
    "        continue\n",
    "\n",
    "    if status == \"free\":\n",
    "        r = math.ceil(delta_h / 5.0)\n",
    "        times = sample_times(r, a, b)\n",
    "        for t in times:\n",
    "            uploads.append([upload_id, uid, random.choice(item_ids_5), t])\n",
    "            upload_id += 1\n",
    "\n",
    "    if status == \"premium\":\n",
    "        r5 = math.ceil(delta_h / 5.0)\n",
    "        times5 = sample_times(r5, a, b)\n",
    "        for t in times5:\n",
    "            uploads.append([upload_id, uid, random.choice(item_ids_5), t])\n",
    "            upload_id += 1\n",
    "\n",
    "        r50 = math.ceil(delta_h / 10.0)\n",
    "        times50 = sample_times(r50, a, b)\n",
    "        for t in times50:\n",
    "            uploads.append([upload_id, uid, random.choice(item_ids_50), t])\n",
    "            upload_id += 1\n",
    "\n",
    "        burst_end = min(a + timedelta(hours=1), b)\n",
    "        for _ in range(10):\n",
    "            if random.random() < 0.5:\n",
    "                t = rand_dt(a, burst_end)\n",
    "                uploads.append([upload_id, uid, random.choice(item_ids_50), t])\n",
    "                upload_id += 1\n",
    "\n",
    "# ----------------------------\n",
    "# Write CSVs\n",
    "# ----------------------------\n",
    "with open(USERS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"user_id\", \"name\"])\n",
    "    w.writerows(users)\n",
    "\n",
    "with open(ITEMS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"item_id\", \"size_gb\"])\n",
    "    w.writerows(items)\n",
    "\n",
    "with open(TIERS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"tier_status_id\", \"user_id\", \"from_datetime\", \"until_datetime\", \"status\"])\n",
    "    for tr in tiers:\n",
    "        w.writerow([\n",
    "            tr[0],\n",
    "            tr[1],\n",
    "            tr[2].strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            tr[3].strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            tr[4]\n",
    "        ])\n",
    "\n",
    "with open(UPLOADS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"upload_id\", \"user_id\", \"item_id\", \"datetime\"])\n",
    "    for up in uploads:\n",
    "        w.writerow([\n",
    "            up[0],\n",
    "            up[1],\n",
    "            up[2],\n",
    "            up[3].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        ])\n",
    "\n",
    "print(\"Done. Wrote:\", USERS_CSV, ITEMS_CSV, TIERS_CSV, UPLOADS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "770fddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(USERS_CSV)\n",
    "tiers_df = pd.read_csv(TIERS_CSV)\n",
    "items_df = pd.read_csv(ITEMS_CSV)\n",
    "uploads_df = pd.read_csv(UPLOADS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db00f94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>User 002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User 003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      name\n",
       "0        1  User 001\n",
       "1        2  User 002\n",
       "2        3  User 003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier_status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>from_datetime</th>\n",
       "      <th>until_datetime</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tier_status_id  user_id         from_datetime        until_datetime  \\\n",
       "0               1        1  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z   \n",
       "1               2        2  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z   \n",
       "2               3        3  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z   \n",
       "\n",
       "    status  \n",
       "0  premium  \n",
       "1  premium  \n",
       "2  premium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>size_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  size_gb\n",
       "0        1        5\n",
       "1        2        5\n",
       "2        3        5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upload_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-03-02T04:10:15Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2025-03-05T08:33:38Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-03-05T04:11:04Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upload_id  user_id  item_id              datetime\n",
       "0          1        1       35  2025-03-02T04:10:15Z\n",
       "1          2        1       16  2025-03-05T08:33:38Z\n",
       "2          3        1       11  2025-03-05T04:11:04Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(users_df.head(3))\n",
    "display(tiers_df.head(3))\n",
    "display(items_df.head(3))\n",
    "display(uploads_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bef8fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n",
      "90 90\n",
      "80 80\n",
      "3181 3181\n"
     ]
    }
   ],
   "source": [
    "print(users_df.shape[0], users_df['user_id'].nunique())\n",
    "print(tiers_df.shape[0], tiers_df['tier_status_id'].nunique())\n",
    "print(items_df.shape[0], items_df['item_id'].nunique())\n",
    "print(uploads_df.shape[0], uploads_df['upload_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d6ca779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier_status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>from_datetime</th>\n",
       "      <th>until_datetime</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-02T09:15:26Z</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>2025-03-02T09:15:26Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tier_status_id  user_id         from_datetime        until_datetime  \\\n",
       "44              45       33  2025-03-01T00:00:00Z  2025-03-02T09:15:26Z   \n",
       "45              46       33  2025-03-02T09:15:26Z  2025-03-11T00:00:00Z   \n",
       "\n",
       "     status  \n",
       "44     free  \n",
       "45  premium  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 33\n",
    "tiers_df.loc[tiers_df.user_id == uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ed1182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upload_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>size_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2028</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-03T20:17:31Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2034</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-03-03T22:00:42Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2071</td>\n",
       "      <td>33</td>\n",
       "      <td>78</td>\n",
       "      <td>2025-03-04T00:24:00Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2027</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-04T04:12:17Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2042</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-04T04:19:48Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2031</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-03-04T09:56:51Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2030</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-04T11:36:43Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2080</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>2025-03-04T15:59:51Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2033</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-03-04T17:23:34Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2040</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>2025-03-04T20:04:14Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2082</td>\n",
       "      <td>33</td>\n",
       "      <td>75</td>\n",
       "      <td>2025-03-04T22:49:46Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2032</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-03-04T22:58:29Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2070</td>\n",
       "      <td>33</td>\n",
       "      <td>65</td>\n",
       "      <td>2025-03-05T03:39:17Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2044</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-03-05T12:22:20Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2075</td>\n",
       "      <td>33</td>\n",
       "      <td>47</td>\n",
       "      <td>2025-03-05T15:43:54Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2053</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-03-05T17:42:24Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2065</td>\n",
       "      <td>33</td>\n",
       "      <td>69</td>\n",
       "      <td>2025-03-05T18:54:51Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2072</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>2025-03-06T00:46:43Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2063</td>\n",
       "      <td>33</td>\n",
       "      <td>77</td>\n",
       "      <td>2025-03-06T01:31:43Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2064</td>\n",
       "      <td>33</td>\n",
       "      <td>79</td>\n",
       "      <td>2025-03-06T03:49:40Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    upload_id  user_id  item_id              datetime  size_gb\n",
       "20       2028       33        7  2025-03-03T20:17:31Z        5\n",
       "21       2034       33       27  2025-03-03T22:00:42Z        5\n",
       "22       2071       33       78  2025-03-04T00:24:00Z       50\n",
       "23       2027       33        7  2025-03-04T04:12:17Z        5\n",
       "24       2042       33        3  2025-03-04T04:19:48Z        5\n",
       "25       2031       33       19  2025-03-04T09:56:51Z        5\n",
       "26       2030       33        7  2025-03-04T11:36:43Z        5\n",
       "27       2080       33       61  2025-03-04T15:59:51Z       50\n",
       "28       2033       33       23  2025-03-04T17:23:34Z        5\n",
       "29       2040       33       39  2025-03-04T20:04:14Z        5\n",
       "30       2082       33       75  2025-03-04T22:49:46Z       50\n",
       "31       2032       33       35  2025-03-04T22:58:29Z        5\n",
       "32       2070       33       65  2025-03-05T03:39:17Z       50\n",
       "33       2044       33       18  2025-03-05T12:22:20Z        5\n",
       "34       2075       33       47  2025-03-05T15:43:54Z       50\n",
       "35       2053       33       26  2025-03-05T17:42:24Z        5\n",
       "36       2065       33       69  2025-03-05T18:54:51Z       50\n",
       "37       2072       33       71  2025-03-06T00:46:43Z       50\n",
       "38       2063       33       77  2025-03-06T01:31:43Z       50\n",
       "39       2064       33       79  2025-03-06T03:49:40Z       50"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = uploads_df.loc[uploads_df.user_id == uid].sort_values(by='datetime').copy()\n",
    "tmp = tmp.merge(items_df)\n",
    "tmp.head(40).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier_status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>from_datetime</th>\n",
       "      <th>until_datetime</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-09T18:14:47Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-03-09T18:14:47Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tier_status_id  user_id         from_datetime        until_datetime  \\\n",
       "20              21       21  2025-03-01T00:00:00Z  2025-03-09T18:14:47Z   \n",
       "21              22       21  2025-03-09T18:14:47Z  2025-03-11T00:00:00Z   \n",
       "\n",
       "     status  \n",
       "20  premium  \n",
       "21     free  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp.head(80).tail(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dce18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69966c58",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- items is only 2 rows. We do not distinguish between items: just make it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807bf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: users.csv, tiers.csv, items.csv, uploads.csv\n",
      "Integrity check passed: No 50GB uploads while free.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate a small relational dataset (CSV) for graph + prediction testing.\n",
    "\n",
    "Tables:\n",
    "- users(user_id PK, name)\n",
    "- tiers(user_id FK, from_datetime, until_datetime, tier)  # composite PK (user_id, from_datetime)\n",
    "- items(item_id PK, size_gb)                              # exactly two rows: (1,5), (2,50)\n",
    "- uploads(txn_id PK, user_id FK, item_id FK, datetime)\n",
    "\n",
    "Cohorts (20 users each):\n",
    "1) Always premium\n",
    "2) Always free\n",
    "3) Premium -> Free (once)\n",
    "4) Free -> Premium (once)\n",
    "5) Free -> Premium -> Free (twice; each change >= 24h apart)\n",
    "\n",
    "Behavior:\n",
    "- While free: uploads only 5GB (item_id=1).\n",
    "- While premium: uploads both 5GB and 50GB (item_id ∈ {1,2}).\n",
    "- Within 1 hour after becoming premium: very high chance (90%) of at least one 50GB upload.\n",
    "- Exactly when/while free: 50GB uploads are impossible.\n",
    "- Upload rates are user-specific and higher on premium than free.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import csv\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# Configuration\n",
    "# ------------------------\n",
    "SEED = 42\n",
    "N_USERS = 50\n",
    "START = datetime(2025, 3, 1, 0, 0, 0, tzinfo=timezone.utc)\n",
    "END = datetime(2025, 3, 11, 0, 0, 0, tzinfo=timezone.utc)  # end-exclusive (covers Mar 1–10)\n",
    "MIN_GAP_BETWEEN_TIER_CHANGES = timedelta(hours=24)\n",
    "\n",
    "# Upload rate modeling (per-hour) via user-specific lognormal draws\n",
    "FREE_RATE_DAY_MEAN = 1.0   # typical free uploads per day\n",
    "FREE_RATE_DAY_STD = 0.7\n",
    "PREM_RATE_DAY_MEAN = 3.0   # typical premium uploads per day\n",
    "PREM_RATE_DAY_STD = 1.0\n",
    "\n",
    "# Size selection while premium (outside the \"first hour\" spike)\n",
    "BASE_P50_WHILE_PREMIUM = 0.4  # 40% chance of 50GB for non-spike premium uploads\n",
    "\n",
    "# Spike rules when becoming premium\n",
    "P_SPIKE_50GB_WITHIN_1H = 0.90\n",
    "MAX_SPIKE_50GB = 2  # cap the number of spike 50GB uploads within the first hour\n",
    "\n",
    "# Output files\n",
    "USERS_CSV = \"users.csv\"\n",
    "TIERS_CSV = \"tiers.csv\"\n",
    "ITEMS_CSV = \"items.csv\"\n",
    "UPLOADS_CSV = \"uploads.csv\"\n",
    "\n",
    "# Fixed items table: exactly two rows\n",
    "ITEMS = [\n",
    "    {\"item_id\": 1, \"size_gb\": 5},\n",
    "    {\"item_id\": 2, \"size_gb\": 50},\n",
    "]\n",
    "ITEM_SIZE_BY_ID = {1: 5, 2: 50}\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "@dataclass\n",
    "class TierInterval:\n",
    "    user_id: int\n",
    "    from_dt: datetime\n",
    "    until_dt: datetime  # end-exclusive\n",
    "    tier: str           # 'free' | 'premium'\n",
    "\n",
    "def iso(dt: datetime) -> str:\n",
    "    return dt.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def draw_user_rate(mean_per_day: float, std_per_day: float) -> float:\n",
    "    \"\"\"Draw a user-specific rate (per hour) using a lognormal around mean/std per day.\"\"\"\n",
    "    mean = max(0.01, mean_per_day)\n",
    "    std = max(0.01, std_per_day)\n",
    "    cv2 = (std / mean) ** 2\n",
    "    sigma2 = math.log(cv2 + 1.0)\n",
    "    sigma = math.sqrt(sigma2)\n",
    "    mu = math.log(mean) - 0.5 * sigma2\n",
    "    per_day = np.random.lognormal(mean=mu, sigma=sigma)\n",
    "    return float(per_day / 24.0)\n",
    "\n",
    "def bounded_random_time(start: datetime, end: datetime) -> datetime:\n",
    "    \"\"\"Uniform random time in [start, end).\"\"\"\n",
    "    if end <= start:\n",
    "        return start\n",
    "    span = (end - start).total_seconds()\n",
    "    offs = random.random() * span\n",
    "    return start + timedelta(seconds=offs)\n",
    "\n",
    "def generate_cohort_tiers(user_id: int, cohort: int) -> list[TierInterval]:\n",
    "    \"\"\"Create tier intervals for a single user according to cohort.\"\"\"\n",
    "    t0 = START\n",
    "    tE = END\n",
    "\n",
    "    def random_change_time(low: datetime, high: datetime) -> datetime:\n",
    "        lo = low + MIN_GAP_BETWEEN_TIER_CHANGES\n",
    "        hi = high - MIN_GAP_BETWEEN_TIER_CHANGES\n",
    "        if hi <= lo:\n",
    "            return low + (high - low) / 2\n",
    "        return bounded_random_time(lo, hi)\n",
    "\n",
    "    intervals: list[TierInterval] = []\n",
    "\n",
    "    if cohort == 1:  # Always premium\n",
    "        intervals.append(TierInterval(user_id, t0, tE, \"premium\"))\n",
    "\n",
    "    elif cohort == 2:  # Always free\n",
    "        intervals.append(TierInterval(user_id, t0, tE, \"free\"))\n",
    "\n",
    "    elif cohort == 3:  # Premium -> Free (once)\n",
    "        c1 = random_change_time(t0, tE)\n",
    "        intervals.append(TierInterval(user_id, t0, c1, \"premium\"))\n",
    "        intervals.append(TierInterval(user_id, c1, tE, \"free\"))\n",
    "\n",
    "    elif cohort == 4:  # Free -> Premium (once)\n",
    "        c1 = random_change_time(t0, tE)\n",
    "        intervals.append(TierInterval(user_id, t0, c1, \"free\"))\n",
    "        intervals.append(TierInterval(user_id, c1, tE, \"premium\"))\n",
    "\n",
    "    elif cohort == 5:  # Free -> Premium -> Free\n",
    "        c1 = random_change_time(t0, tE - MIN_GAP_BETWEEN_TIER_CHANGES)\n",
    "        c2_low = c1 + MIN_GAP_BETWEEN_TIER_CHANGES\n",
    "        c2_high = tE\n",
    "        if c2_low + MIN_GAP_BETWEEN_TIER_CHANGES >= c2_high:\n",
    "            c2 = c1 + (tE - c1) / 2\n",
    "        else:\n",
    "            c2 = random_change_time(c2_low, c2_high)\n",
    "        intervals.append(TierInterval(user_id, t0, c1, \"free\"))\n",
    "        intervals.append(TierInterval(user_id, c1, c2, \"premium\"))\n",
    "        intervals.append(TierInterval(user_id, c2, tE, \"free\"))\n",
    "\n",
    "    intervals.sort(key=lambda x: x.from_dt)\n",
    "    fixed: list[TierInterval] = []\n",
    "    prev_end = None\n",
    "    for it in intervals:\n",
    "        if prev_end and it.from_dt < prev_end:\n",
    "            it = TierInterval(it.user_id, prev_end, it.until_dt, it.tier)\n",
    "        prev_end = it.until_dt\n",
    "        fixed.append(it)\n",
    "    return fixed\n",
    "\n",
    "def simulate_uploads_for_interval(user_id: int,\n",
    "                                  interval: TierInterval,\n",
    "                                  free_rate_per_hour: float,\n",
    "                                  prem_rate_per_hour: float,\n",
    "                                  next_txn_id: int) -> tuple[list[dict], int]:\n",
    "    \"\"\"\n",
    "    Simulate uploads for a single interval.\n",
    "    Returns uploads_rows, next_txn_id\n",
    "    \"\"\"\n",
    "    uploads_rows: list[dict] = []\n",
    "    tier = interval.tier\n",
    "    rate_per_hour = free_rate_per_hour if tier == \"free\" else prem_rate_per_hour\n",
    "\n",
    "    # Hourly grid across [from, until)\n",
    "    cursor = interval.from_dt\n",
    "    while cursor < interval.until_dt:\n",
    "        hour_end = min(cursor + timedelta(hours=1), interval.until_dt)\n",
    "        lam = rate_per_hour * (hour_end - cursor).total_seconds() / 3600.0\n",
    "        n = np.random.poisson(lam=lam) if lam > 0 else 0\n",
    "        for _ in range(n):\n",
    "            ts = bounded_random_time(cursor, hour_end)\n",
    "            if tier == \"free\":\n",
    "                item_id = 1  # 5 GB only\n",
    "            else:\n",
    "                # Premium outside spike window: choose with base probability\n",
    "                item_id = 2 if random.random() < BASE_P50_WHILE_PREMIUM else 1\n",
    "            uploads_rows.append({\n",
    "                \"txn_id\": next_txn_id,\n",
    "                \"user_id\": user_id,\n",
    "                \"item_id\": item_id,\n",
    "                \"datetime\": iso(ts)\n",
    "            })\n",
    "            next_txn_id += 1\n",
    "        cursor = hour_end\n",
    "\n",
    "    # Spike: within first hour after becoming premium\n",
    "    if tier == \"premium\":\n",
    "        became_premium_now = interval.from_dt > START\n",
    "        if became_premium_now and random.random() < P_SPIKE_50GB_WITHIN_1H:\n",
    "            spike_window_end = min(interval.from_dt + timedelta(hours=1), interval.until_dt)\n",
    "            if spike_window_end > interval.from_dt:\n",
    "                n_spike = 1 + (1 if (MAX_SPIKE_50GB > 1 and random.random() < 0.15) else 0)\n",
    "                for _ in range(n_spike):\n",
    "                    ts = bounded_random_time(interval.from_dt, spike_window_end)\n",
    "                    uploads_rows.append({\n",
    "                        \"txn_id\": next_txn_id,\n",
    "                        \"user_id\": user_id,\n",
    "                        \"item_id\": 2,  # force 50 GB in spike\n",
    "                        \"datetime\": iso(ts)\n",
    "                    })\n",
    "                    next_txn_id += 1\n",
    "\n",
    "    return uploads_rows, next_txn_id\n",
    "\n",
    "def main():\n",
    "    # Users\n",
    "    users = [{\"user_id\": uid, \"name\": f\"User {uid:03d}\"} for uid in range(1, N_USERS + 1)]\n",
    "\n",
    "    # Cohorts by user_id blocks of 20\n",
    "    def cohort_of(uid: int) -> int:\n",
    "        return (uid - 1) // 20 + 1  # 1..5\n",
    "\n",
    "    # User-specific rates\n",
    "    free_rate_per_hour = {u[\"user_id\"]: draw_user_rate(FREE_RATE_DAY_MEAN, FREE_RATE_DAY_STD) for u in users}\n",
    "    prem_rate_per_hour = {u[\"user_id\"]: draw_user_rate(PREM_RATE_DAY_MEAN, PREM_RATE_DAY_STD) for u in users}\n",
    "\n",
    "    # Tier intervals\n",
    "    tiers: list[TierInterval] = []\n",
    "    for u in users:\n",
    "        tiers.extend(generate_cohort_tiers(u[\"user_id\"], cohort_of(u[\"user_id\"])))\n",
    "    tiers.sort(key=lambda t: (t.user_id, t.from_dt))\n",
    "\n",
    "    # Simulate uploads\n",
    "    uploads_rows: list[dict] = []\n",
    "    next_txn_id = 1\n",
    "    for t in tiers:\n",
    "        ups, next_txn_id = simulate_uploads_for_interval(\n",
    "            user_id=t.user_id,\n",
    "            interval=t,\n",
    "            free_rate_per_hour=free_rate_per_hour[t.user_id],\n",
    "            prem_rate_per_hour=prem_rate_per_hour[t.user_id],\n",
    "            next_txn_id=next_txn_id\n",
    "        )\n",
    "        uploads_rows.extend(ups)\n",
    "\n",
    "    # Sort uploads by time (optional neatness)\n",
    "    uploads_rows.sort(key=lambda r: (r[\"user_id\"], r[\"datetime\"]))\n",
    "    # Re-assign txn_ids sequentially\n",
    "    for i, r in enumerate(uploads_rows, start=1):\n",
    "        r[\"txn_id\"] = i\n",
    "\n",
    "    # Write CSVs\n",
    "    with open(USERS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"user_id\", \"name\"])\n",
    "        w.writeheader()\n",
    "        w.writerows(users)\n",
    "\n",
    "    with open(TIERS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"user_id\", \"from_datetime\", \"until_datetime\", \"tier\"])\n",
    "        w.writeheader()\n",
    "        for t in tiers:\n",
    "            w.writerow({\n",
    "                \"user_id\": t.user_id,\n",
    "                \"from_datetime\": iso(t.from_dt),\n",
    "                \"until_datetime\": iso(t.until_dt),\n",
    "                \"tier\": t.tier\n",
    "            })\n",
    "\n",
    "    with open(ITEMS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"item_id\", \"size_gb\"])\n",
    "        w.writeheader()\n",
    "        w.writerows(ITEMS)\n",
    "\n",
    "    with open(UPLOADS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"txn_id\", \"user_id\", \"item_id\", \"datetime\"])\n",
    "        w.writeheader()\n",
    "        w.writerows(uploads_rows)\n",
    "\n",
    "    # Integrity check: no 50GB while free\n",
    "    by_user = {}\n",
    "    for t in tiers:\n",
    "        by_user.setdefault(t.user_id, []).append(t)\n",
    "\n",
    "    def tier_at(user_id: int, dt_str: str) -> str:\n",
    "        dt = datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=timezone.utc)\n",
    "        for it in by_user[user_id]:\n",
    "            if it.from_dt <= dt < it.until_dt:\n",
    "                return it.tier\n",
    "        return \"unknown\"\n",
    "\n",
    "    violations = []\n",
    "    for up in uploads_rows:\n",
    "        t = tier_at(up[\"user_id\"], up[\"datetime\"])\n",
    "        size = ITEM_SIZE_BY_ID[up[\"item_id\"]]\n",
    "        if t == \"free\" and size == 50:\n",
    "            violations.append(up)\n",
    "\n",
    "    print(f\"Generated: {USERS_CSV}, {TIERS_CSV}, {ITEMS_CSV}, {UPLOADS_CSV}\")\n",
    "    if violations:\n",
    "        print(f\"[WARNING] Found {len(violations)} violations (50GB while free).\")\n",
    "    else:\n",
    "        print(\"Integrity check passed: No 50GB uploads while free.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2531fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5: [('2025-03-01T00:00:00Z', '2025-03-11T00:00:00Z', 'premium')]\n",
      "User 25: [('2025-03-01T00:00:00Z', '2025-03-11T00:00:00Z', 'free')]\n",
      "User 45: [('2025-03-01T00:00:00Z', '2025-03-07T21:24:08Z', 'premium'), ('2025-03-07T21:24:08Z', '2025-03-11T00:00:00Z', 'free')]\n",
      "User 85: []\n"
     ]
    }
   ],
   "source": [
    "def get_user_tier_summary(user_id: int, tiers_csv: str = \"tiers.csv\"):\n",
    "    \"\"\"\n",
    "    Return a list of (start_iso, end_iso, tier) covering the user’s tier evolution.\n",
    "    - start/end are ISO-8601 UTC strings: 'YYYY-MM-DDTHH:MM:SSZ'\n",
    "    - tier is 'free' or 'premium'\n",
    "    \"\"\"\n",
    "    # Load and filter\n",
    "    tiers = pd.read_csv(tiers_csv)\n",
    "    tiers = tiers[tiers[\"user_id\"] == user_id].copy()\n",
    "    if tiers.empty:\n",
    "        return []  # unknown user_id\n",
    "\n",
    "    # Parse/normalize\n",
    "    tiers[\"from_datetime\"] = pd.to_datetime(tiers[\"from_datetime\"], utc=True)\n",
    "    tiers[\"until_datetime\"] = pd.to_datetime(tiers[\"until_datetime\"], utc=True)\n",
    "    tiers = tiers.sort_values([\"from_datetime\", \"until_datetime\", \"tier\"])\n",
    "\n",
    "    # Optional: coalesce adjacent intervals with the same tier\n",
    "    merged = []\n",
    "    for _, row in tiers.iterrows():\n",
    "        start, end, tier = row[\"from_datetime\"], row[\"until_datetime\"], row[\"tier\"]\n",
    "        if not merged:\n",
    "            merged.append([start, end, tier])\n",
    "        else:\n",
    "            last_start, last_end, last_tier = merged[-1]\n",
    "            # If same tier and touching (no gap), merge\n",
    "            if tier == last_tier and start == last_end:\n",
    "                merged[-1][1] = end\n",
    "            else:\n",
    "                merged.append([start, end, tier])\n",
    "\n",
    "    # Format to tuples with ISO-8601 Zulu\n",
    "    out = [(s.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            e.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            t) for s, e, t in merged]\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- examples ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Always-Free or Always-Premium users will yield one tuple\n",
    "    # Mixed cohorts will yield 2 or 3 tuples\n",
    "\n",
    "    print(\"User 5:\", get_user_tier_summary(5))\n",
    "    print(\"User 25:\", get_user_tier_summary(25))\n",
    "    print(\"User 45:\", get_user_tier_summary(45))\n",
    "    print(\"User 85:\", get_user_tier_summary(85))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "68a95c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"tiers.csv\")\n",
    "# df.insert(0, \"tier_id\", range(1, len(df) + 1))\n",
    "# df.to_csv(\"tiers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1784f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(USERS_CSV)\n",
    "tiers_df = pd.read_csv(TIERS_CSV)\n",
    "items_df = pd.read_csv(ITEMS_CSV)\n",
    "uploads_df = pd.read_csv(UPLOADS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832d1d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User 001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>User 002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User 003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      name\n",
       "0        1  User 001\n",
       "1        2  User 002\n",
       "2        3  User 003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc83f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>size_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  size_gb\n",
       "0        1        5\n",
       "1        2       50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433d48ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>size_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01T04:13:07Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-01T08:01:35Z</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01T08:38:59Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   txn_id  user_id  item_id              datetime  size_gb\n",
       "0       1        1        1  2025-03-01T04:13:07Z        5\n",
       "1       2        1        2  2025-03-01T08:01:35Z       50\n",
       "2       3        1        1  2025-03-01T08:38:59Z        5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploads_df.head(3)\n",
    "uploads_df = uploads_df.merge(items_df, on=\"item_id\", how=\"left\")\n",
    "uploads_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f77813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27331331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>from_datetime</th>\n",
       "      <th>until_datetime</th>\n",
       "      <th>tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-01T00:00:00Z</td>\n",
       "      <td>2025-03-11T00:00:00Z</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         from_datetime        until_datetime     tier\n",
       "0        1  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z  premium\n",
       "1        2  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z  premium\n",
       "2        3  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z  premium\n",
       "3        4  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z  premium\n",
       "4        5  2025-03-01T00:00:00Z  2025-03-11T00:00:00Z  premium"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c8ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime columns are parsed\n",
    "uploads_df[\"datetime\"] = pd.to_datetime(uploads_df[\"datetime\"], utc=True)\n",
    "tiers_df[\"from_datetime\"] = pd.to_datetime(tiers_df[\"from_datetime\"], utc=True)\n",
    "tiers_df[\"until_datetime\"] = pd.to_datetime(tiers_df[\"until_datetime\"], utc=True)\n",
    "\n",
    "# Merge on user_id\n",
    "merged = uploads_df.merge(tiers_df[['user_id', 'from_datetime', 'until_datetime', 'tier']], on=\"user_id\", how=\"left\")\n",
    "\n",
    "# Filter for intervals\n",
    "uploads_df = merged[\n",
    "    (merged[\"datetime\"] >= merged[\"from_datetime\"]) &\n",
    "    (merged[\"datetime\"] <  merged[\"until_datetime\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c19153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45712/1162197868.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uploads_df.drop(columns=[\"from_datetime\", \"until_datetime\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "uploads_df.drop(columns=[\"from_datetime\", \"until_datetime\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f0934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>size_gb</th>\n",
       "      <th>tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01 04:13:07+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-01 08:01:35+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-01 08:38:59+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   txn_id  user_id  item_id                  datetime  size_gb     tier\n",
       "0       1        1        1 2025-03-01 04:13:07+00:00        5  premium\n",
       "1       2        1        2 2025-03-01 08:01:35+00:00       50  premium\n",
       "2       3        1        1 2025-03-01 08:38:59+00:00        5  premium"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploads_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c7f12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected primary key 'user_id' in table 'users'\n",
      "Detected primary key 'item_id' in table 'items'\n",
      "Detected time column 'datetime' in table 'uploads'\n"
     ]
    }
   ],
   "source": [
    "users = rfm.LocalTable(users_df, name=\"users\").infer_metadata()\n",
    "#tiers = rfm.LocalTable(tiers_df, name=\"tiers\").infer_metadata()\n",
    "items = rfm.LocalTable(items_df, name=\"items\").infer_metadata()\n",
    "uploads = rfm.LocalTable(uploads_df, name=\"uploads\").infer_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a9d2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploads['size_gb'].stype = \"numerical\"\n",
    "uploads['txn_id'].stype = \"ID\"\n",
    "# Set primary key:\n",
    "uploads.primary_key = \"txn_id\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3560701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 🏷️ Metadata of Table `users` (50 rows)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0f43a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0f43a_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_0f43a_level0_col1\" class=\"col_heading level0 col1\" >dtype</th>\n",
       "      <th id=\"T_0f43a_level0_col2\" class=\"col_heading level0 col2\" >stype</th>\n",
       "      <th id=\"T_0f43a_level0_col3\" class=\"col_heading level0 col3\" >is_primary_key</th>\n",
       "      <th id=\"T_0f43a_level0_col4\" class=\"col_heading level0 col4\" >is_time_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0f43a_row0_col0\" class=\"data row0 col0\" >user_id</td>\n",
       "      <td id=\"T_0f43a_row0_col1\" class=\"data row0 col1\" >int</td>\n",
       "      <td id=\"T_0f43a_row0_col2\" class=\"data row0 col2\" >ID</td>\n",
       "      <td id=\"T_0f43a_row0_col3\" class=\"data row0 col3\" >True</td>\n",
       "      <td id=\"T_0f43a_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f43a_row1_col0\" class=\"data row1 col0\" >name</td>\n",
       "      <td id=\"T_0f43a_row1_col1\" class=\"data row1 col1\" >string</td>\n",
       "      <td id=\"T_0f43a_row1_col2\" class=\"data row1 col2\" >text</td>\n",
       "      <td id=\"T_0f43a_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "      <td id=\"T_0f43a_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af581633d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 🏷️ Metadata of Table `items` (2 rows)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_57e99\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_57e99_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_57e99_level0_col1\" class=\"col_heading level0 col1\" >dtype</th>\n",
       "      <th id=\"T_57e99_level0_col2\" class=\"col_heading level0 col2\" >stype</th>\n",
       "      <th id=\"T_57e99_level0_col3\" class=\"col_heading level0 col3\" >is_primary_key</th>\n",
       "      <th id=\"T_57e99_level0_col4\" class=\"col_heading level0 col4\" >is_time_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_57e99_row0_col0\" class=\"data row0 col0\" >item_id</td>\n",
       "      <td id=\"T_57e99_row0_col1\" class=\"data row0 col1\" >int</td>\n",
       "      <td id=\"T_57e99_row0_col2\" class=\"data row0 col2\" >ID</td>\n",
       "      <td id=\"T_57e99_row0_col3\" class=\"data row0 col3\" >True</td>\n",
       "      <td id=\"T_57e99_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_57e99_row1_col0\" class=\"data row1 col0\" >size_gb</td>\n",
       "      <td id=\"T_57e99_row1_col1\" class=\"data row1 col1\" >int</td>\n",
       "      <td id=\"T_57e99_row1_col2\" class=\"data row1 col2\" >categorical</td>\n",
       "      <td id=\"T_57e99_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "      <td id=\"T_57e99_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af08a17f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 🏷️ Metadata of Table `uploads` (896 rows)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b9f38\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b9f38_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_b9f38_level0_col1\" class=\"col_heading level0 col1\" >dtype</th>\n",
       "      <th id=\"T_b9f38_level0_col2\" class=\"col_heading level0 col2\" >stype</th>\n",
       "      <th id=\"T_b9f38_level0_col3\" class=\"col_heading level0 col3\" >is_primary_key</th>\n",
       "      <th id=\"T_b9f38_level0_col4\" class=\"col_heading level0 col4\" >is_time_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row0_col0\" class=\"data row0 col0\" >txn_id</td>\n",
       "      <td id=\"T_b9f38_row0_col1\" class=\"data row0 col1\" >int</td>\n",
       "      <td id=\"T_b9f38_row0_col2\" class=\"data row0 col2\" >ID</td>\n",
       "      <td id=\"T_b9f38_row0_col3\" class=\"data row0 col3\" >True</td>\n",
       "      <td id=\"T_b9f38_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row1_col0\" class=\"data row1 col0\" >user_id</td>\n",
       "      <td id=\"T_b9f38_row1_col1\" class=\"data row1 col1\" >int</td>\n",
       "      <td id=\"T_b9f38_row1_col2\" class=\"data row1 col2\" >ID</td>\n",
       "      <td id=\"T_b9f38_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "      <td id=\"T_b9f38_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row2_col0\" class=\"data row2 col0\" >item_id</td>\n",
       "      <td id=\"T_b9f38_row2_col1\" class=\"data row2 col1\" >int</td>\n",
       "      <td id=\"T_b9f38_row2_col2\" class=\"data row2 col2\" >ID</td>\n",
       "      <td id=\"T_b9f38_row2_col3\" class=\"data row2 col3\" >False</td>\n",
       "      <td id=\"T_b9f38_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row3_col0\" class=\"data row3 col0\" >datetime</td>\n",
       "      <td id=\"T_b9f38_row3_col1\" class=\"data row3 col1\" >date</td>\n",
       "      <td id=\"T_b9f38_row3_col2\" class=\"data row3 col2\" >timestamp</td>\n",
       "      <td id=\"T_b9f38_row3_col3\" class=\"data row3 col3\" >False</td>\n",
       "      <td id=\"T_b9f38_row3_col4\" class=\"data row3 col4\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row4_col0\" class=\"data row4 col0\" >size_gb</td>\n",
       "      <td id=\"T_b9f38_row4_col1\" class=\"data row4 col1\" >int</td>\n",
       "      <td id=\"T_b9f38_row4_col2\" class=\"data row4 col2\" >numerical</td>\n",
       "      <td id=\"T_b9f38_row4_col3\" class=\"data row4 col3\" >False</td>\n",
       "      <td id=\"T_b9f38_row4_col4\" class=\"data row4 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b9f38_row5_col0\" class=\"data row5 col0\" >tier</td>\n",
       "      <td id=\"T_b9f38_row5_col1\" class=\"data row5 col1\" >string</td>\n",
       "      <td id=\"T_b9f38_row5_col2\" class=\"data row5 col2\" >categorical</td>\n",
       "      <td id=\"T_b9f38_row5_col3\" class=\"data row5 col3\" >False</td>\n",
       "      <td id=\"T_b9f38_row5_col4\" class=\"data row5 col4\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af581633d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users.print_metadata()\n",
    "#tiers.print_metadata()\n",
    "items.print_metadata()\n",
    "uploads.print_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "20d5928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = rfm.LocalGraph(tables=[users, tiers, items, uploads])\n",
    "graph = rfm.LocalGraph(tables=[users, items, uploads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f0a2083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.link(src_table=\"tiers\", fkey=\"user_id\", dst_table=\"users\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "655d81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.link(src_table=\"uploads\", fkey=\"item_id\", dst_table=\"items\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aeb4c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.link(src_table=\"uploads\", fkey=\"user_id\", dst_table=\"users\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8c559519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 🕸️ Graph Links (FK ↔️ PK)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- `uploads.item_id` ↔️ `items.item_id`\n",
       "- `uploads.user_id` ↔️ `users.user_id`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.print_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b457efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 10: [('2025-03-01T00:00:00Z', '2025-03-11T00:00:00Z', 'premium')]\n",
      "User 30: [('2025-03-01T00:00:00Z', '2025-03-11T00:00:00Z', 'free')]\n",
      "User 50: [('2025-03-01T00:00:00Z', '2025-03-02T05:43:15Z', 'premium'), ('2025-03-02T05:43:15Z', '2025-03-11T00:00:00Z', 'free')]\n",
      "User 70: [('2025-03-01T00:00:00Z', '2025-03-06T19:54:55Z', 'free'), ('2025-03-06T19:54:55Z', '2025-03-11T00:00:00Z', 'premium')]\n",
      "User 90: [('2025-03-01T00:00:00Z', '2025-03-03T03:27:05Z', 'free'), ('2025-03-03T03:27:05Z', '2025-03-06T23:40:35Z', 'premium'), ('2025-03-06T23:40:35Z', '2025-03-11T00:00:00Z', 'free')]\n"
     ]
    }
   ],
   "source": [
    "print(\"User 10:\", get_user_tier_summary(10))\n",
    "print(\"User 30:\", get_user_tier_summary(30))\n",
    "print(\"User 50:\", get_user_tier_summary(50))\n",
    "print(\"User 70:\", get_user_tier_summary(70))\n",
    "print(\"User 90:\", get_user_tier_summary(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "73803f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rfm.KumoRFM(graph, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3e00e946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>ANCHOR_TIMESTAMP</th>\n",
       "      <th>TARGET_PRED</th>\n",
       "      <th>False_PROB</th>\n",
       "      <th>True_PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2025-03-08T00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.564697</td>\n",
       "      <td>0.435303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY     ANCHOR_TIMESTAMP  TARGET_PRED  False_PROB  True_PROB\n",
       "0      10  2025-03-08T00:00:00        False    0.564697   0.435303"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"PREDICT MAX(uploads.size_gb, 0, 3, hours)=50 FOR users.user_id = 10\"\"\"\n",
    "model.predict(query, anchor_time=pd.Timestamp(\"2025-03-08\"), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2b8e880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>ANCHOR_TIMESTAMP</th>\n",
       "      <th>TARGET_PRED</th>\n",
       "      <th>False_PROB</th>\n",
       "      <th>True_PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>2025-03-05T00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.834076</td>\n",
       "      <td>0.165924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY     ANCHOR_TIMESTAMP  TARGET_PRED  False_PROB  True_PROB\n",
       "0      30  2025-03-05T00:00:00        False    0.834076   0.165924"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"PREDICT MAX(uploads.size_gb, 0, 3, hours)=50 FOR users.user_id = 30\"\"\"\n",
    "model.predict(query, anchor_time=pd.Timestamp(\"2025-03-05\"), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c451ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/graph_ML_and_deep_learning_on_RDBs/venv/lib/python3.10/site-packages/kumoai/experimental/rfm/rfm.py:360: UserWarning: Anchor timestamp is too early or aggregation time range is too large. To form proper input data, we would need data back to '2025-02-28 23:43:15', however, your data only contains data back to '2025-03-01 00:10:31'.\n",
      "  warnings.warn(f\"Anchor timestamp is too early or aggregation \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>ANCHOR_TIMESTAMP</th>\n",
       "      <th>TARGET_PRED</th>\n",
       "      <th>False_PROB</th>\n",
       "      <th>True_PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2025-03-01T05:43:15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.647296</td>\n",
       "      <td>0.352704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY     ANCHOR_TIMESTAMP  TARGET_PRED  False_PROB  True_PROB\n",
       "0      50  2025-03-01T05:43:15        False    0.647296   0.352704"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"PREDICT MAX(uploads.size_gb, 0, 3, hours)=50 FOR users.user_id = 50\"\"\"\n",
    "model.predict(query, anchor_time=pd.Timestamp(\"2025-03-01 05:43:15\"), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cce915c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY</th>\n",
       "      <th>ANCHOR_TIMESTAMP</th>\n",
       "      <th>TARGET_PRED</th>\n",
       "      <th>False_PROB</th>\n",
       "      <th>True_PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>2025-03-06T20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.655193</td>\n",
       "      <td>0.344807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY     ANCHOR_TIMESTAMP  TARGET_PRED  False_PROB  True_PROB\n",
       "0      70  2025-03-06T20:00:00        False    0.655193   0.344807"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"\"\"PREDICT MAX(uploads.size_gb, 0, 1, hours)=50 FOR users.user_id = 70\"\"\"\n",
    "model.predict(query, anchor_time=pd.Timestamp(\"2025-03-06 20:00:00\"), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb067f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
